---
title: "myopia"
author: "jb4686"
date: "5/7/2022"
output: pdf_document
---



```{r}
library(pacman)
p_load(tidyverse, data.table, fs, tictoc, lubridate, beepr,dplyr,skimr, rpart,tidymodels,dplyr, forcats, rsample, Boruta, randomForest, splitTools, ROCit, rminer, parsnip, yardstick, caret, gbm)
```
## import dataset


```{r}
myopia <- read.csv("myopia.csv")
head(myopia)
```

## split data

```{r}
library(splitTools)
split<- partition(myopia$MYOPIC, p = c(train = 0.7, valid = 0.15, test = 0.15))

train2 <- myopia[split$train, ]
valid2 <- myopia[split$valid, ]
test2 <- myopia[split$test, ]

```



## Factor reponse variable

```{r}
train2$MYOPIC <- as.factor(train2$MYOPIC)
test2$MYOPIC <- as.factor(test2$MYOPIC)
valid2$MYOPIC <- as.factor(valid2$MYOPIC)
```

```{r}
train2$MOMMY <- as.factor(train2$MOMMY)
test2$MOMMY <- as.factor(test2$MOMMY)
valid2$MOMMY <- as.factor(valid2$MOMMY)
```


```{r}
train2$DADMY <- as.factor(train2$DADMY)
test2$DADMY <- as.factor(test2$DADMY)
valid2$DADMY <- as.factor(valid2$DADMY)
```

## Feature Selection with logistic regression

```{r}
glm<- glm(MYOPIC ~ STUDYYEAR+ AGE + GENDER + SPHEQ + AL + ACD + LT + VCD + SPORTHR + READHR + COMPHR+STUDYHR+ TVHR+DIOPTERHR+ MOMMY + DADMY, data = myopia, family = binomial)
```



```{r}
library(gbm)
varImp(glm)
```

## Feature Selection with random Forest

```{r}
rf <- randomForest(MYOPIC ~ STUDYYEAR+ AGE + GENDER + SPHEQ + AL + ACD + LT + VCD + SPORTHR + READHR + COMPHR+STUDYHR+ TVHR+DIOPTERHR+ MOMMY + DADMY, data=myopia,importance=TRUE, ntree=250)
varImp(rf)
varImpPlot(rf)
```

## Fit Random Forest

```{r}
library(randomForest)
library(rpart)
set.seed(10)
formula <- as.formula(MYOPIC ~ STUDYYEAR+ GENDER + SPHEQ +SPORTHR + READHR + COMPHR+STUDYHR+ DIOPTERHR+ MOMMY + DADMY)
mod_forest1 <- rand_forest(
  mode = "classification", 
  mtry = 10, 
  trees = 500
) %>%
  set_engine("randomForest") %>%
  fit(formula, data = train2)

```


## Accuracy 


```{r}
library(yardstick)
set.seed(10)
pred_sample1 <- valid2 %>%
  select(MYOPIC) %>%
  bind_cols(
    predict(mod_forest1, new_data = valid2 , type = "class")
  ) %>%
  rename(myopia_tree_matrix = .pred_class)
  
pred_sample1 %>%
  conf_mat(MYOPIC, myopia_tree_matrix)
pred_sample1 %>%
  accuracy(MYOPIC, myopia_tree_matrix)
```



```{r}
library(yardstick)
set.seed(10)
pred2 <- test2%>%
  select(MYOPIC) %>%
  bind_cols(
    predict(mod_forest1, new_data = test2, type = "class")
  ) %>%
  rename(myopia_tree_matrix2 = .pred_class)
pred2  %>%
  conf_mat(MYOPIC, myopia_tree_matrix2)
pred2 %>%
  accuracy(MYOPIC, myopia_tree_matrix2)
```

### cross validation and Accuracy


```{r}
library(caret)
set.seed(10)
ctrl <- trainControl(method = "repeatedcv",
                     number = 5, repeats = 10)
# auto-tune a random forest
grid_rf <- expand.grid(.mtry = c(1, 2, 3, 4, 5, 6))
set.seed(1000)
m_rf1_test <- train(formula, data = valid2, method = "rf",
              metric = "Kappa", trControl = ctrl,
              tuneGrid = grid_rf)


myopia_pred_traindata <- predict(m_rf1_test, valid2)
confusionMatrix(data=myopia_pred_traindata,valid2$MYOPIC)
myopiapred_testdata <- predict(m_rf1_test,test2)
confusionMatrix(data=myopiapred_testdata, test2$MYOPIC)
```




## GLM model

```{r}

library(tidyverse)
set.seed(10)
formula <- as.formula(MYOPIC ~ AGE + GENDER + SPHEQ +SPORTHR + READHR + COMPHR+STUDYHR+ TVHR+ MOMMY + DADMY)

myopia_glm <- logistic_reg(penalty = 0.001, mixture = 0.5) %>% 
  set_engine("glmnet") %>%
  set_mode("classification") %>%
  fit(formula, data = train2)

myopia_glm %>%
  predict(valid2) %>%
  rename(myopia_logistic_validation = .pred_class)%>%
  bind_cols(valid2$MYOPIC) %>%
  accuracy(valid2$MYOPIC, myopia_logistic_validation)

```


## Testing accuracy

```{r}
set.seed(10)
myopia_glm %>%
  predict(test2) %>%
  rename(myopia_logistic_test = .pred_class)%>%
  bind_cols(test2$MYOPIC) %>%
  accuracy(test2$MYOPIC, myopia_logistic_test)

```

## cross validate GLM

```{r}
library(caret)
set.seed(10)
# auto-tune a random forest

formula <- as.formula(MYOPIC ~ AGE + GENDER + SPHEQ +SPORTHR + READHR + COMPHR+STUDYHR+ TVHR+ MOMMY + DADMY)

set.seed(1000)
ctrl <- trainControl(method = "repeatedcv",
                     number = 6, repeats = 10)
glm_test <- train(formula, data=train2, method='glm', trControl = ctrl, 
                    tuneGrid=expand.grid(parameter=c(0.001, 0.01, 0.1, 1,10,100, 1000)))


myopia_pred_traindata2 <- predict(glm_test, valid2)
confusionMatrix(data=myopia_pred_traindata2,valid2$MYOPIC)
myopiapred_testdata2 <- predict(glm_test,test2)
confusionMatrix(data=myopiapred_testdata2, test2$MYOPIC)


```


```{r}
summary(glm_test)
```

```{r}
glm_test$finalModel
```

## Prediction
```{r}

new_data<- data.frame(AGE = 10, GENDER = 0, SPHEQ = 0, SPORTHR = 40, READHR = 10, COMPHR = 10, STUDYHR = 20, TVHR = 5, MOMMY = "1" , DADMY = "1")
predict(glm_test, new_data, type = "prob")

```

## Interpretation

$$\widehat{log(Myopia)} = 43.7636 -2.0811 AGE -0.3685 GENDER -6.8455 SPHEQ - 0.0682 SPORTHR + 0.3876 READHR + 0.1026 COMPHR - 0.3666 STUDYHR + 0.2080 TVHR+ 0.3638 MOMMY + 0.5317 DADMY$$



